{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "from pyts.image import RecurrencePlot, GramianAngularField, MarkovTransitionField\n",
    "from sklearn.metrics import accuracy_score\n",
    "import gc\n",
    "from modified_originial_attlstm import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List files\n",
    "\n",
    "files = glob.glob('data.*')\n",
    "files_train = files[:-2]\n",
    "files_test = files[1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training / Testing batch\n",
    "\n",
    "columns = ['time', 'b1', 'b2', 'b3', 'b4', 'b5', 'b6', 'b7', 'b8', 'b9',\n",
    "       'b10', 'b11', 'b12', 'b13', 'b14', 'b15', 'b16', 'b17', 'b18', 'b19',\n",
    "       'b20', 'b21', 'b22', 'b23', 'b24', 'b25', 'b26', 'b27', 'b28', 'b29',\n",
    "       'b30', 'b31', 'b32', 'b33', 'b34', 'b35', 'b36', 'b37', 'b38', 'b39',\n",
    "       'b40', 'b41', 's1', 's2', 's3', 's4', 's5', 's6', 's7', 's8', 's9',\n",
    "       's10', 's11', 's12', 's13', 's14', 's15', 's16', 's17', 's18', 's19',\n",
    "       's20', 's21', 's22', 's23', 's24', 's25', 's26', 's27', 's28', 's29',\n",
    "       's30', 's31', 's32', 's33', 's34', 's35', 's36', 's37', 's38', 's39',\n",
    "       's40', 's41', 's42', 's43', 's44', 's45', 's46', 's47', 's48', 's49',\n",
    "       's50', 'y_1m', 'y_5m', 'y_10m', 'y_15m', 'y_30m', 'y_hat1', 'y_hat2',\n",
    "       'y_hat3']\n",
    "for i in range(len(files_train)):\n",
    "    #i=0\n",
    "    #File loading\n",
    "    if i == 0:\n",
    "        df = pd.read_csv(files_train[i])\n",
    "        df.columns = columns\n",
    "    else:\n",
    "        df = pd.read_csv(files_train[i],names=columns)\n",
    "    test = pd.read_csv(files_test[i],header=None,names=columns)\n",
    "\n",
    "    #Preprocessing\n",
    "    df = df.set_index(pd.DatetimeIndex(pd.to_datetime(df[df.columns[0]])))\n",
    "    target = df.y_10m\n",
    "    df = df.drop(['s19','s24','time',\"y_1m\",\"y_5m\",\"y_10m\",\"y_15m\",\"y_30m\",\"y_hat1\",\"y_hat2\",\"y_hat3\"],axis=1)\n",
    "    df = df.fillna(0)\n",
    "\n",
    "    test = test.set_index(pd.DatetimeIndex(pd.to_datetime(test[test.columns[0]])))\n",
    "    target_test = test.y_10m\n",
    "    test = test.drop(['s19','s24','time',\"y_1m\",\"y_5m\",\"y_10m\",\"y_15m\",\"y_30m\",\"y_hat1\",\"y_hat2\",\"y_hat3\"],axis=1)\n",
    "    test = test.fillna(0)\n",
    "    test2 = np.array(test)\n",
    "\n",
    "    #TRAINING\n",
    "    batchsize = 128\n",
    "    nhidden_encoder = 128\n",
    "    nhidden_decoder = 128\n",
    "    ntimestep = 2\n",
    "    lr = 0.001\n",
    "    epochs = 50\n",
    "    model = DA_RNN(\n",
    "        np.array(df),\n",
    "        np.array(target),\n",
    "        ntimestep,\n",
    "        nhidden_encoder,\n",
    "        nhidden_decoder,\n",
    "        batchsize,\n",
    "        lr,\n",
    "        epochs,\n",
    "        parallel=True\n",
    "    )\n",
    "    print(\"==> Start training ...\")\n",
    "    model.train()\n",
    "    #TESTING\n",
    "    y_pred = model.test(test2,target_test)\n",
    "    #print(\"accuracy_score\" + str(accuracy_score(np.sign(np.array(target_test)),np.sign(y_pred))))\n",
    "    lin = np.linspace(0,1,5)\n",
    "    print(pd.DataFrame(y_pred).quantile(lin))\n",
    "    print(\"cor: \" + str(np.corrcoef(target_test,y_pred)[0,1]))\n",
    "    pd.DataFrame({'index':test.index,'y_pred':y_pred,'target_test':target_test}).to_csv(\"attlstm\" + str(i) + \".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate predictions\n",
    "\n",
    "files = glob.glob('attlstm*')[1:]\n",
    "for i,file in enumerate(files):\n",
    "    df = pd.read_csv(file)\n",
    "    df = df.set_index(pd.DatetimeIndex(pd.to_datetime(df[df.columns[0]]))) \n",
    "    df =df.y_pred\n",
    "    if i == 0:\n",
    "        all_df = df\n",
    "    else:\n",
    "        all_df = pd.concat((all_df,df))\n",
    "all_df.to_csv('all_attlstm.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NO NEED EVERYTHING BELOW\n",
    "\n",
    "files = glob.glob('results/attlstm*')[1:]\n",
    "for i,file in enumerate(files):\n",
    "    df = pd.read_csv(file)\n",
    "    df = df.set_index(pd.DatetimeIndex(pd.to_datetime(df[df.columns[0]]))) \n",
    "    df =df.y_pred\n",
    "    if i == 0:\n",
    "        all_df = df\n",
    "    else:\n",
    "        all_df = pd.concat((all_df,df))\n",
    "all_df.to_csv('all_xg.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minMax(x):\n",
    "    returnurn pd.Series(index=['min','max'],data=[x.min(),x.max()])\n",
    "minMax = df.apply(minMax).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['time', 'b1', 'b2', 'b3', 'b4', 'b5', 'b6', 'b7', 'b8', 'b9',\n",
    "       'b10', 'b11', 'b12', 'b13', 'b14', 'b15', 'b16', 'b17', 'b18', 'b19',\n",
    "       'b20', 'b21', 'b22', 'b23', 'b24', 'b25', 'b26', 'b27', 'b28', 'b29',\n",
    "       'b30', 'b31', 'b32', 'b33', 'b34', 'b35', 'b36', 'b37', 'b38', 'b39',\n",
    "       'b40', 'b41', 's1', 's2', 's3', 's4', 's5', 's6', 's7', 's8', 's9',\n",
    "       's10', 's11', 's12', 's13', 's14', 's15', 's16', 's17', 's18', 's19',\n",
    "       's20', 's21', 's22', 's23', 's24', 's25', 's26', 's27', 's28', 's29',\n",
    "       's30', 's31', 's32', 's33', 's34', 's35', 's36', 's37', 's38', 's39',\n",
    "       's40', 's41', 's42', 's43', 's44', 's45', 's46', 's47', 's48', 's49',\n",
    "       's50', 'y_1m', 'y_5m', 'y_10m', 'y_15m', 'y_30m', 'y_hat1', 'y_hat2',\n",
    "       'y_hat3']\n",
    "df = pd.read_csv(files_train[0])\n",
    "test = pd.read_csv(files_test[0],header=None,names=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.set_index(pd.DatetimeIndex(pd.to_datetime(df[df.columns[0]])))\n",
    "target = df.y_10m\n",
    "df = df.drop(['s19','s24','Unnamed: 0',\"y_1m\",\"y_5m\",\"y_10m\",\"y_15m\",\"y_30m\",\"y_hat1\",\"y_hat2\",\"y_hat3\"],axis=1)\n",
    "df = df.fillna(0)\n",
    "df2 = np.array(df.tail(10000))\n",
    "test = test.set_index(pd.DatetimeIndex(pd.to_datetime(test[test.columns[0]])))\n",
    "target_test = test.y_10m\n",
    "test = test.drop(['s19','s24','time',\"y_1m\",\"y_5m\",\"y_10m\",\"y_15m\",\"y_30m\",\"y_hat1\",\"y_hat2\",\"y_hat3\"],axis=1)\n",
    "test = test.fillna(0)\n",
    "test2 = np.array(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = RecurrencePlot()\n",
    "df_temp1 = transformer.fit_transform(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer2 = GramianAngularField()\n",
    "df_temp2 = transformer2.fit_transform(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer3 = MarkovTransitionField()\n",
    "df_temp3 = transformer3.fit_transform(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = (df_temp1+df_temp2+df_temp3)/3\n",
    "df2 = np.array(df2).reshape(len(df2),df2.shape[1] * df2.shape[1])\n",
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xg\n",
    "model = xg.XGBRegressor(verbose=2,gpu_id=0,nthread=8)\n",
    "model.fit(np.array(df2[-1000:]),np.array(target.tail(1000)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test2 = transformer.transform(test[10000:20000])\n",
    "\n",
    "df2 = (df_temp1+df_temp2+df_temp3)/3\n",
    "test2 = np.array(test2).reshape(len(test2),test2.shape[1] * test2.shape[1])\n",
    "y_pred = model.predict(test2)\n",
    "print(\"accuracy_score\" + str(accuracy_score(np.sign(np.array(target_test[10000:20000])),np.sign(y_pred))))\n",
    "#lin = np.linspace(0,1,101)\n",
    "#print(pd.DataFrame(y_pred).quantile(lin))\n",
    "print(\"cor\" + str(np.corrcoef(target_test[10000:20000],y_pred)[0,1]))\n",
    "pd.DataFrame({'index':test.index[10000:20000],'y_pred':y_pred,'target_test':target_test[10000:20000]}).to_csv(\"xg\" + str(0) + \".csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
