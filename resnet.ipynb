{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "from pyts.image import RecurrencePlot, GramianAngularField, MarkovTransitionField\n",
    "from sklearn.metrics import accuracy_score\n",
    "import gc\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from resnet import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up GPU environment \n",
    "\n",
    "if 'session' in locals() and session is not None:\n",
    "    print('Close interactive session')\n",
    "    session.close()\n",
    "_SESSION = None\n",
    "if _SESSION is None:\n",
    "    if not os.environ.get('OMP_NUM_THREADS'):\n",
    "        config = tf.ConfigProto(allow_soft_placement=True)\n",
    "        config.gpu_options.allow_growth=True\n",
    "    else:\n",
    "        num_thread = int(os.environ.get('OMP_NUM_THREADS'))\n",
    "        config = tf.ConfigProto(intra_op_parallelism_threads=num_thread,\n",
    "                                allow_soft_placement=True)\n",
    "        config.gpu_options.allow_growth=True\n",
    "    _SESSION = tf.Session(config=config)\n",
    "session = _SESSION\n",
    "set_session(session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List files\n",
    "\n",
    "files = glob.glob('data.*')\n",
    "files_train = files[:-2]\n",
    "files_test = files[1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# First training\n",
    "\n",
    "columns = ['time', 'b1', 'b2', 'b3', 'b4', 'b5', 'b6', 'b7', 'b8', 'b9',\n",
    "       'b10', 'b11', 'b12', 'b13', 'b14', 'b15', 'b16', 'b17', 'b18', 'b19',\n",
    "       'b20', 'b21', 'b22', 'b23', 'b24', 'b25', 'b26', 'b27', 'b28', 'b29',\n",
    "       'b30', 'b31', 'b32', 'b33', 'b34', 'b35', 'b36', 'b37', 'b38', 'b39',\n",
    "       'b40', 'b41', 's1', 's2', 's3', 's4', 's5', 's6', 's7', 's8', 's9',\n",
    "       's10', 's11', 's12', 's13', 's14', 's15', 's16', 's17', 's18', 's19',\n",
    "       's20', 's21', 's22', 's23', 's24', 's25', 's26', 's27', 's28', 's29',\n",
    "       's30', 's31', 's32', 's33', 's34', 's35', 's36', 's37', 's38', 's39',\n",
    "       's40', 's41', 's42', 's43', 's44', 's45', 's46', 's47', 's48', 's49',\n",
    "       's50', 'y_1m', 'y_5m', 'y_10m', 'y_15m', 'y_30m', 'y_hat1', 'y_hat2',\n",
    "       'y_hat3']\n",
    "#for i in range(len(files_train)):\n",
    "i=0\n",
    "#File loading\n",
    "if i == 0:\n",
    "    df = pd.read_csv(files_train[i])\n",
    "    df.columns = columns\n",
    "else:\n",
    "    df = pd.read_csv(files_train[i],names=columns)\n",
    "test = pd.read_csv(files_test[i],header=None,names=columns)\n",
    "\n",
    "#Preprocessing\n",
    "df = df.set_index(pd.DatetimeIndex(pd.to_datetime(df[df.columns[0]])))#[-1000:]\n",
    "target = df.y_10m\n",
    "df = df.drop(['s19','s24','time',\"y_1m\",\"y_5m\",\"y_10m\",\"y_15m\",\"y_30m\",\"y_hat1\",\"y_hat2\",\"y_hat3\"],axis=1)\n",
    "df = df.fillna(0)\n",
    "\n",
    "test = test.set_index(pd.DatetimeIndex(pd.to_datetime(test[test.columns[0]]))) #[:15000]\n",
    "target_test = test.y_10m\n",
    "test = test.drop(['s19','s24','time',\"y_1m\",\"y_5m\",\"y_10m\",\"y_15m\",\"y_30m\",\"y_hat1\",\"y_hat2\",\"y_hat3\"],axis=1)\n",
    "test = test.fillna(0)\n",
    "test2 = np.array(test)\n",
    "\n",
    "# transformer = RecurrencePlot()\n",
    "# df_temp1 = transformer.fit_transform(df)\n",
    "# transformer2 = GramianAngularField()\n",
    "# df_temp2 = transformer2.fit_transform(df)\n",
    "# transformer3 = MarkovTransitionField()\n",
    "# df_temp3 = transformer3.fit_transform(df)\n",
    "# df2 = (df_temp1+df_temp2+df_temp3)/3\n",
    "\n",
    "X_train = np.array(df).reshape(df.shape + (1,1,))\n",
    "y_train = (np.array(target).reshape(len(target),1) - np.mean(target))/np.std(target)\n",
    "\n",
    "# df_temp1 = transformer.transform(test2)\n",
    "# transformer2 = GramianAngularField()\n",
    "# df_temp2 = transformer2.transform(test2)\n",
    "# transformer3 = MarkovTransitionField()\n",
    "# df_temp3 = transformer3.transform(test2)\n",
    "# test2 = (df_temp1+df_temp2+df_temp3)/3\n",
    "\n",
    "X_test = np.array(test2).reshape(test2.shape + (1,1,))\n",
    "y_test = (np.array(target_test).reshape(len(target_test),1) - np.mean(target))/np.std(target)\n",
    "\n",
    "x , y = build_resnet(X_train.shape[1:], 64, 1)\n",
    "model = keras.models.Model(inputs=x, outputs=y)\n",
    "print(model.summary())\n",
    "optimizer = keras.optimizers.Adam()\n",
    "\n",
    "\n",
    "if i == 0:\n",
    "    model.compile(loss='mse',\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=['mse'])\n",
    "    reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='loss', factor=0.5,\n",
    "                  patience=2, min_lr=0.0001) \n",
    "    hist = model.fit(X_train, y_train, batch_size=512,epochs=20,\n",
    "        #sample_weight=target_train**2+1e-16,\n",
    "        #validation_data=(X_test, y_test),  #,target**2+1e-16\n",
    "        verbose=1, callbacks = [reduce_lr])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Resnet Weights\n",
    "model.save('resnet.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check predictions quantiles if stable enough\n",
    "y_pred = model.predict(X_test,verbose=1)\n",
    "lin = np.linspace(0,1,5)\n",
    "print(pd.DataFrame(y_pred).quantile(lin))\n",
    "print(\"cor: \" + str(np.corrcoef(target_test,y_pred)[0,1]))\n",
    "pd.DataFrame({'index':test.index,'y_pred':y_pred,'target_test':target_test}).to_csv(\"resnet\" + str(i) + \".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unstandardized regression\n",
    "y_pred2 = (np.concatenate(y_pred)*np.std(target))+np.mean(target)\n",
    "lin = np.linspace(0,1,5)\n",
    "print(pd.DataFrame(y_pred2).quantile(lin))\n",
    "print(\"cor: \" + str(np.corrcoef(target_test,y_pred2)[0,1]))\n",
    "pd.DataFrame({'index':test.index,'y_pred':y_pred2,'target_test':target_test}).to_csv(\"resnet\" + str(i) + \".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Training / Testing batch\n",
    "for i in range(1,len(files_train)):\n",
    "    test = pd.read_csv(files_test[i],header=None,names=columns)\n",
    "    test = test.set_index(pd.DatetimeIndex(pd.to_datetime(test[test.columns[0]]))) #[:15000]\n",
    "    target_test = test.y_10m\n",
    "    test = test.drop(['s19','s24','time',\"y_1m\",\"y_5m\",\"y_10m\",\"y_15m\",\"y_30m\",\"y_hat1\",\"y_hat2\",\"y_hat3\"],axis=1)\n",
    "    test = test.fillna(0)\n",
    "    test2 = np.array(test)\n",
    "    X_test = np.array(test2).reshape(test2.shape + (1,1,))\n",
    "    y_test = (np.array(target_test).reshape(len(target_test),1) - np.mean(target))/np.std(target)\n",
    "    y_pred = model.predict(X_test,verbose=1)\n",
    "    y_pred = (np.concatenate(y_pred)*np.std(target))+np.mean(target)\n",
    "    lin = np.linspace(0,1,5)\n",
    "    print(pd.DataFrame(y_pred).quantile(lin))\n",
    "    print(\"cor: \" + str(np.corrcoef(target_test,y_pred)[0,1]))\n",
    "    pd.DataFrame({'index':test.index,'y_pred':y_pred,'target_test':target_test}).to_csv(\"resnet\" + str(i) + \".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenating all predictions\n",
    "files = glob.glob('resnet*.csv')\n",
    "for i,file in enumerate(files):\n",
    "    df = pd.read_csv(file)\n",
    "    df = df.set_index(pd.DatetimeIndex(pd.to_datetime(df[df.columns[0]]))) \n",
    "    df =df.y_pred\n",
    "    if i == 0:\n",
    "        all_df = df\n",
    "    else:\n",
    "        all_df = pd.concat((all_df,df))\n",
    "all_df.to_csv('all_resnet.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Averaging all predictions\n",
    "files = ['all_rocket.csv','all_attlstm.csv','all_resnet.csv']\n",
    "df = pd.read_csv(files[0])\n",
    "df = df.set_index(pd.DatetimeIndex(pd.to_datetime(df[df.columns[0]]))) \n",
    "df2 = pd.read_csv(files[1])\n",
    "df2 = df2.set_index(pd.DatetimeIndex(pd.to_datetime(df2[df2.columns[0]]))) \n",
    "df3 = pd.read_csv(files[2])\n",
    "df3 = df3.set_index(pd.DatetimeIndex(pd.to_datetime(df3[df3.columns[0]])))\n",
    "all_df = (df.IF + df2.IF + df3.IF) /3\n",
    "all_df.to_csv('all_att_rocket_resnet.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
